{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd539a4e",
   "metadata": {},
   "source": [
    "# DEOCSU - DEep-learning Optimized ChIP-exo peak calling SUite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3d7c5",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\"> Environmental setup </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b54239",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "0. python 3 (https://www.python.org/)\n",
    "--------------------------------------\n",
    "Download the python package using\n",
    "- anaconda : https://anaconda.org/\n",
    "- pip : https://pypi.org/\n",
    "--------------------------------------\n",
    "1. pandas (https://pandas.pydata.org/)\n",
    "2. cv2 (https://opencv.org/)\n",
    "3. matplotlib (https://matplotlib.org/)\n",
    "4. tensorflow (https://www.tensorflow.org/)<br>\n",
    "    -keras (https://keras.io/)<br>\n",
    "    -scipy (https://scipy.org/)<br>\n",
    "    -numpy (https://numpy.org/)<br>\n",
    "5. statsmodels (https://www.statsmodels.org/)\n",
    "6. sklearn (https://scikit-learn.org/)\n",
    "7. Biopython (https://biopython.org/)\n",
    "8. pysam (https://github.com/pysam-developers/pysam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae1279",
   "metadata": {},
   "source": [
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256ce9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time, itertools, pysam, math, getpass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from Bio import SeqIO\n",
    "from numpy import zeros\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca7ff6",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> ↓↓ Please change the directory of the input file ↓↓ </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c46ac",
   "metadata": {},
   "source": [
    "# Input file\n",
    "\n",
    "1. Download the genbank(full) format reference file from NCBI database\n",
    ">https://www.ncbi.nlm.nih.gov/\n",
    "\n",
    "\n",
    "\n",
    "2. BAM format file \n",
    "> - BAM file must be sorted and indexed using samtools.<br>\n",
    "> - If replicate data doesn't exist, write **None** as dir_bam2\n",
    "\n",
    "\n",
    "# Probability cut-off value\n",
    "> - When it is None, it is calculated automatically.<br>\n",
    "> - Please input a value between 0.5 and 1.0 to designate a specific value as the cut-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19536f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output directory\n",
    "dir_notebook = \"/home/ina/DEOCSU-test/\"\n",
    "dir_model = \"/home/ina/DEOCSU-test/DEOCSU_model.h5\"\n",
    "\n",
    "##Input file directory\n",
    "dir_reference = dir_notebook + \"Input/NC_000913.gb\" #NCBI genbank(full) file\n",
    "dir_bam1 = dir_notebook + \"Input/MG1655_RpoN-1.bam\" #replicate 1\n",
    "dir_bam2 = dir_notebook + \"Input/MG1655_RpoN-2.bam\" #replicate 2\n",
    "#dir_bam2 = None #replicate 2 (If it doesn't exist, write None)\n",
    "\n",
    "##Output file name\n",
    "output_name = \"MG1655_RpoN\"\n",
    "\n",
    "##Probability cut-off value. \n",
    "cut_off = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca63fde9",
   "metadata": {},
   "source": [
    "# Running the code [Please do not change the code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a986844",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘DEOCSU_temp’: File exists\n",
      "mkdir: cannot create directory ‘DEOCSU_output’: File exists\n",
      "Making the reference files - Done ฅ^•ﻌ•^ฅ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E::idx_find_and_load] Could not retrieve index file for '/home/ina/DEOCSU-test/Input/MG1655_RpoN-1.bam'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makegff - Done ฅ^•ﻌ•^ฅ\n",
      "Temp file - Done ฅ^•ﻌ•^ฅ\n",
      "MG1655_RpoN\n",
      "Detected raw peak = 8309\n",
      "Peak detection - Done ฅ^•ﻌ•^ฅ\n",
      "Making window - Done ฅ^•ﻌ•^ฅ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 12:30:53.962693: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing - Done ฅ^•ﻌ•^ฅ\n",
      "Make peak gff - Done ฅ^•ﻌ•^ฅ\n"
     ]
    }
   ],
   "source": [
    "os.chdir(dir_notebook)\n",
    "!mkdir \"DEOCSU_temp\" \"DEOCSU_output\"\n",
    "dir_temp = dir_notebook + \"DEOCSU_temp/\"\n",
    "dir_output = dir_notebook + \"DEOCSU_output/\"\n",
    "\n",
    "###########################################If a permission denied error occurs, run this cell instead of the cell above.\n",
    "\"\"\"\n",
    "print (\"Write your admin password :\")\n",
    "os.chdir(dir_notebook)\n",
    "command = \"sudo mkdir \\\"DEOCSU_temp\\\" \\\"DEOCSU_output\\\"\"\n",
    "!echo {getpass.getpass()} | sudo -S {command}\n",
    "\"\"\"\n",
    "###########################################\n",
    "\n",
    "#Making the reference files\n",
    "dic_len = {}\n",
    "ref_info = \".\".join(dir_reference.split(\"/\")[-1].split(\".\")[:-1])\n",
    "\n",
    "with open(\"%sAnnotation_%s.gff\"%(dir_output, ref_info), \"w\") as f_rgff:\n",
    "    genomes = SeqIO.parse( dir_reference, \"genbank\")\n",
    "    for genome in genomes:\n",
    "        #Chromosome size\n",
    "        dic_len[ genome.id ] = int(len(genome.seq))\n",
    "        \n",
    "        #Annotation file for metascope (.gff)\n",
    "        dic_info = {}\n",
    "        for gene in genome.features:\n",
    "            if gene.type == \"CDS\":\n",
    "                cds_locus =  gene.qualifiers.get(\"locus_tag\")[0]\n",
    "                cds_product, cds_protein = \"-\", \"-\"\n",
    "                if gene.qualifiers.get(\"product\") != None:\n",
    "                    cds_product = gene.qualifiers.get(\"product\")[0]\n",
    "                if gene.qualifiers.get(\"protein_id\") != None:\n",
    "                    cds_protein_id = gene.qualifiers.get(\"protein_id\")[0]\n",
    "\n",
    "                if cds_locus in dic_info.keys():\n",
    "                    cds_w2 = \"Other_info;protein_id=%s;product=%s;color=000000;\"%(cds_protein_id, cds_product)\n",
    "                    new_info = dic_info[ cds_locus ].replace( \"color=00A500;\", cds_w2 )\n",
    "                    dic_info[ cds_locus ] = new_info\n",
    "\n",
    "                else:\n",
    "                    cds_w = \"type=CDS;protein_id=%s;product=%s;color=00A500;\"%(cds_protein_id, cds_product)\n",
    "                    dic_info[ cds_locus ] = cds_w\n",
    "\n",
    "            elif gene.type in ['rRNA','tRNA','ncRNA','tmRNA'] :\n",
    "                rna_locus = gene.qualifiers.get(\"locus_tag\")[0]\n",
    "                rna_product = \"-\"\n",
    "                if gene.qualifiers.get(\"product\") != None:\n",
    "                    rna_product = gene.qualifiers.get(\"product\")[0]\n",
    "\n",
    "                if rna_locus in dic_info.keys():\n",
    "                    rna_w2 = \"Other_info;product=%s;color=000000;\"%( rna_product )\n",
    "                    newinfo = dic_info[ rna_locus ].replace( \"color=FF0000;\", rna_w2 )\n",
    "                    dic_info[ rna_locus ] = newinfo\n",
    "\n",
    "                else:\n",
    "                    rna_w = \"type=%s;product=%s;color=FF0000;\"%( gene.type, rna_product )\n",
    "                    dic_info[ rna_locus ] = rna_w\n",
    "\n",
    "        #write_gff\n",
    "        for gene in genome.features:\n",
    "            if gene.type == \"gene\":\n",
    "                gene_locus = gene.qualifiers.get(\"locus_tag\")[0]\n",
    "                if gene.qualifiers.get(\"gene\") != None:\n",
    "                    gene_name = gene.qualifiers.get(\"gene\")[0]\n",
    "                if gene.qualifiers.get(\"gene_synonym\") != None:\n",
    "                    syn = gene.qualifiers.get(\"gene_synonym\")[0].split(\"; \")\n",
    "                    gene_name += \",%s\"%(\",\".join(syn))\n",
    "                else: gene_name = \"-\"\n",
    "                start = str(gene.location.start +1)\n",
    "                end = str(gene.location.end)\n",
    "                if gene.strand == 1: strand = \"+\"\n",
    "                elif gene.strand == -1: strand = \"-\"\n",
    "                else: print (\"===========================Gene_Strand information is weird!!! %s\"%gene.strand)\n",
    "                if gene_locus in dic_info.keys():\n",
    "                    add_info = dic_info[gene_locus]\n",
    "                else: \n",
    "                    add_info = \"color=000000;\"\n",
    "                attr = \"gene=%s;locus_tag=%s;%s\"%(gene_name, gene_locus,add_info)\n",
    "                gff_w = [ genome.id, \"NCBI\",\"NCBI\", start, end, \".\", strand, \".\", attr ] \n",
    "                f_rgff.write( \"\\t\".join(gff_w) + \"\\n\")\n",
    "\n",
    "            elif gene.type == \"regulatory\":\n",
    "                start = str(gene.location.start +1)\n",
    "                end = str(gene.location.end)\n",
    "                if gene.strand == 1: strand = \"+\"\n",
    "                elif gene.strand == -1: strand = \"-\"\n",
    "                else: print (\"===========================Regulatory_Strand information is weird!!! %s\"%gene.strand)\n",
    "                attr = \"type=regulatory;color=0000FF;\"\n",
    "                gff_w = [ genome.id, \"NCBI\",\"NCBI\", start, end, \".\", strand, \".\", attr ]\n",
    "                f_rgff.write( \"\\t\".join(gff_w) + \"\\n\")\n",
    "\n",
    "            elif gene.type == \"repeat_region\":\n",
    "                start = str(gene.location.start +1)\n",
    "                end = str(gene.location.end)\n",
    "                if gene.strand == 1: strand = \"+\"\n",
    "                elif gene.strand == -1: strand = \"-\"\n",
    "                else: print (\"===========================repeat_region_Strand information is weird!!! %s\"%gene.strand)\n",
    "                attr = \"type=repeat_region;color=808080;\"\n",
    "                gff_w = [ genome.id, \"NCBI\",\"NCBI\", start, end, \".\", strand, \".\", attr ]\n",
    "                f_rgff.write( \"\\t\".join(gff_w) + \"\\n\") \n",
    "print (\"Making the reference files - Done ฅ^•ﻌ•^ฅ\")\n",
    "\n",
    "#Makegff\n",
    "def count_coverage(samfile, chromosome_size=8000000, flip=False):\n",
    "    \"\"\"counts coverage per base in a strand-specific manner\n",
    "\n",
    "    For paired-end reads, the insert between the mapped reads is\n",
    "    also counted.\n",
    "\n",
    "    flip: Whether or not the strands should be flipped.\n",
    "    This should be true for RNA-seq, and false for ChIP-exo\n",
    "\n",
    "    chromsome_size: This value should be larger than the largest chromosome\"\"\"\n",
    "    all_counts = {}\n",
    "    plus_strands = []\n",
    "    minus_strands = []\n",
    "    if \"SQ\" in samfile.header:\n",
    "        chromosome_sizes = {}\n",
    "        for entry in samfile.header[\"SQ\"]:\n",
    "            chromosome_sizes[entry[\"SN\"]] = int(entry[\"LN\"]) + 1\n",
    "    else:\n",
    "        for reference in samfile.references:\n",
    "            chromosome_sizes[reference] = chromosome_size\n",
    "    for reference in samfile.references:  # create an array for each reference\n",
    "        plus_strands.append(zeros((chromosome_sizes[reference],)))\n",
    "        minus_strands.append(zeros((chromosome_sizes[reference],)))\n",
    "    # iterate through each mapped read\n",
    "    for i, read in enumerate(samfile):\n",
    "        if read.is_unmapped:\n",
    "            continue\n",
    "        if not read.is_proper_pair:\n",
    "            if read.is_reverse:\n",
    "                minus_strands[read.tid][read.pos:read.aend] += 1\n",
    "            else:\n",
    "                plus_strands[read.tid][read.pos:read.aend] += 1\n",
    "        # for paired-end data, get entire insert from only read1\n",
    "        elif read.is_read1:\n",
    "            if read.is_reverse:\n",
    "                minus_strands[read.tid][read.pnext:read.aend] += 1\n",
    "            else:\n",
    "                plus_strands[read.tid][read.pos:read.pos + read.isize] += 1\n",
    "    # store the results per reference\n",
    "    for i, reference in enumerate(samfile.references):\n",
    "        all_counts[reference] = {}\n",
    "        if flip:\n",
    "            all_counts[reference][\"-\"] = plus_strands[i]\n",
    "            all_counts[reference][\"+\"] = minus_strands[i]\n",
    "        else:\n",
    "            all_counts[reference][\"+\"] = plus_strands[i]\n",
    "            all_counts[reference][\"-\"] = minus_strands[i]\n",
    "    return all_counts\n",
    "\n",
    "def count_coverage_indexed(samfile, chromosome_size=8000000, flip=False):\n",
    "    \"\"\"counts coverage per base in a strand-specific manner\n",
    "\n",
    "    For paired-end reads, the insert between the mapped reads is\n",
    "    also counted.\n",
    "\n",
    "    flip: Whether or not the strands should be flipped.\n",
    "    This should be true for RNA-seq, and false for ChIP-exo\n",
    "\n",
    "    chromsome_size: This value should be larger than the largest chromosome\"\"\"\n",
    "    if \"SQ\" in samfile.header:\n",
    "        chromosome_sizes = {}\n",
    "        for entry in samfile.header[\"SQ\"]:\n",
    "            chromosome_sizes[entry[\"SN\"]] = int(entry[\"LN\"]) + 1\n",
    "    else:\n",
    "        for reference in samfile.references:\n",
    "            chromosome_sizes[reference] = chromosome_size\n",
    "    all_counts = {}\n",
    "    for reference in samfile.references:  # go through each chromosome\n",
    "        plus_strand = zeros((chromosome_sizes[reference],))\n",
    "        minus_strand = zeros((chromosome_sizes[reference],))\n",
    "        # iterate through each mapped read\n",
    "        for i, read in enumerate(samfile.fetch(reference=reference)):\n",
    "            if not read.is_proper_pair:\n",
    "                if read.is_reverse:\n",
    "                    minus_strand[read.pos:read.aend] += 1\n",
    "                else:\n",
    "                    plus_strand[read.pos:read.aend] += 1\n",
    "            # for paired-end data, get entire insert from only read1\n",
    "            elif read.is_read1:\n",
    "                if read.is_reverse:\n",
    "                    minus_strand[read.pnext:read.aend] += 1\n",
    "                else:\n",
    "                    plus_strand[read.pos:read.pos + read.isize] += 1\n",
    "            all_counts[reference] = {}\n",
    "            if flip:\n",
    "                all_counts[reference][\"-\"] = plus_strand\n",
    "                all_counts[reference][\"+\"] = minus_strand\n",
    "            else:\n",
    "                all_counts[reference][\"+\"] = plus_strand\n",
    "                all_counts[reference][\"-\"] = minus_strand\n",
    "    return all_counts\n",
    "\n",
    "\n",
    "def write_samfile_to_gff(samfile, output, chromosome_size=8000000, separate_strand=True, flip=False, log_scale=False):\n",
    "    \"\"\"write samfile object to an output object in a gff format\n",
    "\n",
    "    flip: Whether or not the strands should be flipped.\n",
    "    This should be true for RNA-seq, and false for ChIP-exo\n",
    "\n",
    "    chromsome_size: This value should be larger than the largest chromosome\n",
    "\n",
    "    separate_strand: Whether the forward and reverse strands should be made\n",
    "    into separate tracks (True) or the negative strand should be rendered\n",
    "    as negative values (False)\n",
    "    \"\"\"\n",
    "    all_counts = count_coverage(samfile, chromosome_size=chromosome_size,flip=flip)\n",
    "    name = os.path.split(samfile.filename)[1]\n",
    "    for reference in all_counts:\n",
    "        for strand in all_counts[reference]:\n",
    "            counts = all_counts[reference][strand]\n",
    "            for i in counts.nonzero()[0]:\n",
    "                if log_scale:\n",
    "                    count = math.log(float(counts[i]), 2)\n",
    "                else:\n",
    "                    count = counts[i]\n",
    "                if separate_strand:\n",
    "                    output.write(\"%s\\t\\t%s\\t%d\\t%d\\t%.2f\\t%s\\t.\\t.\\n\" %\n",
    "                        (reference, \"%s_(%s)\" %(name.decode('ascii'), strand), i, i,count, strand))\n",
    "                else:\n",
    "                    output.write(\"%s\\t\\t%s\\t%d\\t%d\\t%.2f\\t%s\\t.\\t.\\n\" %\n",
    "                        (reference, name.decode('ascii'), i, i, count,strand))\n",
    "\n",
    "\n",
    "def convert_samfile_to_gff(sam_filename, out_filename, chromosome_size=8000000,separate_strand=True, flip=False, log_scale=False):\n",
    "    \"\"\"read in the a samfile from a path, and write it out to a gff filepath\n",
    "\n",
    "    flip: Whether or not the strands should be flipped.\n",
    "    This should be true for RNA-seq, and false for ChIP-exo.\n",
    "\n",
    "    chromsome_size: This value should be larger than the largest chromosome.\n",
    "\n",
    "    separate_strand: Whether the forward and reverse strands should be made\n",
    "    into separate tracks (True) or the negative strand should be rendered\n",
    "    as negative values (False)\n",
    "    \"\"\"\n",
    "    samfile = pysam.Samfile(sam_filename)\n",
    "    with open(out_filename, \"w\") as outfile:\n",
    "        write_samfile_to_gff(samfile, outfile, chromosome_size=chromosome_size, separate_strand=separate_strand, flip=flip, log_scale=log_scale)\n",
    "    samfile.close()\n",
    "\n",
    "dir_R1 = dir_output + dir_bam1.split(\"/\")[-1].split(\".bam\")[0] + \".gff\"\n",
    "\n",
    "if dir_bam2 == None:\n",
    "    dir_R2 = None\n",
    "else:\n",
    "    dir_R2 = dir_output + dir_bam2.split(\"/\")[-1].split(\".bam\")[0] + \".gff\"\n",
    "\n",
    "convert_samfile_to_gff( dir_bam1, dir_R1 )\n",
    "\n",
    "if dir_bam2 == None:\n",
    "    pass\n",
    "else: \n",
    "    convert_samfile_to_gff( dir_bam2, dir_R2 )\n",
    "print (\"Makegff - Done ฅ^•ﻌ•^ฅ\")\n",
    "\n",
    "dic_R1, dic_R2 = {}, {}\n",
    "\n",
    "with open( dir_R1, \"r\" ) as R1 :\n",
    "    r1 = R1.read().split(\"\\n\")\n",
    "    for line in r1:\n",
    "        if line == \"\": continue\n",
    "        line = line.split(\"\\t\")\n",
    "        a_num = line[0]\n",
    "        strand = line[6]\n",
    "        start = int(line[3])\n",
    "        score = float( line[5] )\n",
    "        dkey = a_num + \"-%s\"%str(start)\n",
    "\n",
    "        if \"+\" in strand:\n",
    "            if dkey in dic_R1.keys():\n",
    "                dic_R1[ dkey ][0] = score\n",
    "            else:            \n",
    "                dic_R1[ dkey ] = [ score, 0 ]\n",
    "                \n",
    "        elif \"-\" in strand :\n",
    "            if dkey in dic_R1.keys():\n",
    "                dic_R1[ dkey ][1] = score\n",
    "            else:\n",
    "                dic_R1[ dkey ] = [ 0, score ]\n",
    "\n",
    "if dir_R2 == None:\n",
    "    dic_R2 = dic_R1\n",
    "else:\n",
    "    with open( dir_R2, \"r\" ) as R2 :\n",
    "        r2 = R2.read().split(\"\\n\")\n",
    "        for line in r2:\n",
    "            if line == \"\": continue\n",
    "            line = line.split(\"\\t\")\n",
    "            a_num = line[0]\n",
    "            strand = line[6]\n",
    "            start = int(line[3])\n",
    "            score = float( line[5] )\n",
    "            dkey = a_num + \"-%s\"%str(start)\n",
    "\n",
    "            if \"+\" in strand:\n",
    "                if dkey in dic_R2.keys():\n",
    "                    dic_R2[ dkey ][0] = score\n",
    "                else:            \n",
    "                    dic_R2[ dkey ] = [ score, 0 ]\n",
    "\n",
    "            elif \"-\" in strand :\n",
    "                if dkey in dic_R2.keys():\n",
    "                    dic_R2[ dkey ][1] = score\n",
    "                else:\n",
    "                    dic_R2[ dkey ] = [ 0, score ]\n",
    "                \n",
    "dir_raw_csv = dir_temp + output_name + \"_raw.csv\"\n",
    "with open( dir_raw_csv, \"w\") as final :\n",
    "    final.write( \"location,1_plus,1_minus,2_plus,2_minus\\n\" )\n",
    "    \n",
    "    genomes = list(dic_len.keys())\n",
    "    for genome in genomes:\n",
    "        acce = genome\n",
    "        for x in range( 1 , int(dic_len[genome])+1 ):\n",
    "            key = acce + \"-%s\"%str(x)\n",
    "            d1_plus, d1_minus, d2_plus, d2_minus = \"0\",\"0\",\"0\",\"0\"\n",
    "            \n",
    "            if key in dic_R1.keys():\n",
    "                d1_plus = str(dic_R1[key][0])\n",
    "                d1_minus = str(dic_R1[key][1])\n",
    "            \n",
    "            if key in dic_R2.keys():\n",
    "                d2_plus = str(dic_R2[key][0])\n",
    "                d2_minus = str(dic_R2[key][1])\n",
    "            \n",
    "            w = [ key, d1_plus, d1_minus, d2_plus, d2_minus ]\n",
    "            final.write( \",\".join(w) + \"\\n\")\n",
    "dic_R1, dic_R2 = {}, {}\n",
    "print (\"Temp file - Done ฅ^•ﻌ•^ฅ\")\n",
    "\n",
    "#Peak detection\n",
    "dir_peak_csv = dir_temp + output_name + \"_detected_peak.csv\"\n",
    "d1 = pd.read_csv(dir_raw_csv)\n",
    "d_list = [ d1 ]\n",
    "t_list = [ output_name ]\n",
    "\n",
    "for cnt in range(len(d_list)):\n",
    "    print(t_list[cnt])\n",
    "    d = d_list[cnt]\n",
    "    target = d['1_plus']\n",
    "    i = 0\n",
    "    peak_x2_list = []\n",
    "\n",
    "    while True:\n",
    "        t = target[i : i + 10000]\n",
    "        peak_x, properties = find_peaks(t, threshold = 0.0, distance = 400, rel_height = 0.2)\n",
    "        peak_x2 = [j + i for j in peak_x]\n",
    "        peak_x2_list = peak_x2_list + peak_x2\n",
    "\n",
    "        i = i + 10000\n",
    "\n",
    "        if i > len(target):\n",
    "            break\n",
    "            \n",
    "    loc_list = []\n",
    "    raw = d['location'].tolist()\n",
    "    for i in peak_x2_list:\n",
    "        loc = raw[i] # peak_x2_list\n",
    "        loc_list.append(loc)\n",
    "        \n",
    "    df_peak = pd.DataFrame({})\n",
    "    df_peak['location'] = loc_list\n",
    "    print(\"Detected raw peak = %d\"%len(loc_list))\n",
    "    \n",
    "    df_peak.to_csv( dir_peak_csv )\n",
    "print (\"Peak detection - Done ฅ^•ﻌ•^ฅ\")\n",
    "\n",
    "#Making 256 window\n",
    "dir_4duc = dir_temp + output_name + \"_4duc.tsv\"\n",
    "with open(dir_raw_csv, \"r\") as csv,open(dir_peak_csv, \"r\") as peak,open(dir_4duc, \"w\") as final:\n",
    "    w_info = ['location', \"S1_plus\", \"S1_minus\", \"S2_plus\", \"S2_minus\"]\n",
    "    final.write(\"\\t\".join(w_info)+\"\\n\")\n",
    "    #===========================================\n",
    "    dic_csv = {}\n",
    "    clines = csv.read().split(\"\\n\")\n",
    "    for cline in clines:\n",
    "        cline = cline.split(\",\")\n",
    "        dic_csv[cline[0]] = cline[1:]\n",
    "    #===========================================\n",
    "    plines = peak.read().split(\"\\n\")\n",
    "    for pline in plines[1:(len(plines)-1)]:\n",
    "        pline = pline.split(\",\")\n",
    "        acc_loc = pline[1]\n",
    "        #print(acc_loc)\n",
    "        acc = acc_loc.split(\"-\")[0]\n",
    "        peak = int(acc_loc.split(\"-\")[1])\n",
    "\n",
    "        d1_plus, d1_minus, d2_plus, d2_minus = [],[],[],[]\n",
    "\n",
    "        if peak <= 128:\n",
    "            range_info = range(1, peak+128)\n",
    "        elif peak > (dic_len[acc]-128):\n",
    "            range_info = range(peak-128, dic_len[acc])\n",
    "        else:\n",
    "            range_info = range(peak-128, peak+128)\n",
    "\n",
    "        for p in range_info :\n",
    "            loc = \"%s-%d\"%(acc,p)\n",
    "            lst_score = dic_csv[str(loc)]\n",
    "\n",
    "            d1_plus.append(float(lst_score[0]))\n",
    "            d1_minus.append(float(lst_score[1]))\n",
    "            d2_plus.append(float(lst_score[2]))\n",
    "            d2_minus.append(float(lst_score[3]))\n",
    "\n",
    "\n",
    "        w = [acc_loc, str(d1_plus), str(d1_minus), str(d2_plus), str(d2_minus)]\n",
    "        final.write(\"\\t\".join(w)+ \"\\n\")\n",
    "\n",
    "    print (\"Making window - Done ฅ^•ﻌ•^ฅ\")\n",
    "    \n",
    "#Data processing\n",
    "df = pd.read_csv(dir_4duc, sep=\"\\t\")\n",
    "\n",
    "model = load_model(dir_model)\n",
    "\n",
    "S1_p = [eval(i) for i in df['S1_plus'].tolist()]\n",
    "S1_m = [eval(i) for i in df['S1_minus'].tolist()]\n",
    "S2_p = [eval(i) for i in df['S2_plus'].tolist()]\n",
    "S2_m = [eval(i) for i in df['S2_minus'].tolist()]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "rgba_list = []\n",
    "for i in range(len(S1_p)):\n",
    "    r = scaler.fit_transform(np.array(S1_p[i]).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
    "    g = scaler.fit_transform(np.array(S1_m[i]).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
    "    b = scaler.fit_transform(np.array(S2_p[i]).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
    "    a = scaler.fit_transform(np.array(S2_m[i]).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
    "    rgba = np.array([r,g,b,a]).T\n",
    "    rgba_list.append(rgba.tolist())\n",
    "    \n",
    "df['img_raw'] = rgba_list\n",
    "\n",
    "rgba_list_resized = []\n",
    "for i in rgba_list :\n",
    "    resized = cv.resize(np.array(i), dsize = (4,256), interpolation  = cv.INTER_AREA)\n",
    "    rgba_list_resized.append(resized.tolist())\n",
    "df['resized_img'] = rgba_list_resized\n",
    "#===========================================\n",
    "#Calculation wodth and Peak lication correction\n",
    "X = np.array([i for i in df['resized_img'].tolist()])\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "X = X.astype('float32')/255.0\n",
    "\n",
    "predict = model.predict(X)\n",
    "predict_labels = np.argmax(predict, axis = 1)\n",
    "predict_t = np.array(predict).T[1]\n",
    "\n",
    "df['predicted'] = predict_t\n",
    "df['predicted_label'] = predict_labels\n",
    "\n",
    "ans = df['predicted_label'].tolist()\n",
    "pr = np.array( [ i for i in df['predicted'].tolist() ])\n",
    "\n",
    "df['ans'] = ans\n",
    "df['pr'] = pr\n",
    "\n",
    "df_T = df[df['ans'] == 1]\n",
    "df = df[df['predicted_label'] == 1]\n",
    "sp1 = [eval(j) for j in df_T['S1_plus'].tolist()]\n",
    "sm1 = [eval(j) for j in df_T['S1_minus'].tolist()]\n",
    "sp2 = [eval(j) for j in df_T['S2_plus'].tolist()]\n",
    "sm2 = [eval(j) for j in df_T['S2_minus'].tolist()]\n",
    "\n",
    "def differen(data):\n",
    "    a = data.index(max(data))\n",
    "    b = data.index(min(data))\n",
    "    ans = np.abs(a-b)\n",
    "    return ans\n",
    "\n",
    "def Index(data):\n",
    "    a = data.index(max(data))\n",
    "    b = data.index(min(data))\n",
    "    #ans = np.abs(a-b)\n",
    "    return a,b\n",
    "\n",
    "x1_l = []\n",
    "x2_l = []\n",
    "for i in range(len(df_T)):\n",
    "    d1 = np.diff(sp1[i]).tolist()\n",
    "    d2 = np.diff(sm1[i]).tolist()\n",
    "    d3 = np.diff(sp2[i]).tolist()\n",
    "    d4 = np.diff(sm2[i]).tolist()\n",
    "    \n",
    "    a1, b1 = Index(d1)\n",
    "    a2, b2 = Index(d2)\n",
    "    a3, b3 = Index(d3)\n",
    "    a4, b4 = Index(d4)\n",
    "    max_mean = np.mean([a1,a2, a3, a4])\n",
    "    min_mean = np.mean([ b1, b2, b3, b4])\n",
    "\n",
    "    x1_l.append(max_mean)\n",
    "    x2_l.append(min_mean)\n",
    "    \n",
    "re_l = [np.abs(x1_l[i] - x2_l[i]) for i in range(len(x1_l))]\n",
    "    \n",
    "df['x1'] = x1_l\n",
    "df['x2'] = x2_l\n",
    "df['width'] = re_l\n",
    "\n",
    "dir_final_tsv = dir_temp + output_name + \"_final.tsv\"\n",
    "df.to_csv( dir_final_tsv, columns = ['location', 'predicted_label', 'predicted', 'width', 'x1', 'x2'], index=False, sep=\"\\t\")\n",
    "print (\"Data processing - Done ฅ^•ﻌ•^ฅ\")\n",
    "\n",
    "#make peak gff\n",
    "\n",
    "if cut_off == None:\n",
    "    df_cut = df[['predicted', 'width']]\n",
    "    thresh = np.linspace(50,99,50).tolist()  # threshold candidate probability\n",
    "    std_list = []\n",
    "\n",
    "    for i in thresh : \n",
    "        d_target  = df[df_cut['predicted'] > (i/100)]\n",
    "        wi = d_target['width'].tolist()\n",
    "        std_wi = np.std(wi)\n",
    "        std_list.append(std_wi) \n",
    "\n",
    "    x = np.array([i for i in range(len(std_list))])\n",
    "    y = np.array(std_list)\n",
    "    \n",
    "    x1 = 0\n",
    "    y1 = std_list[0]\n",
    "    x2 = len(std_list)\n",
    "    y2 = std_list[-1]\n",
    "\n",
    "    def straight_line(x1,x2,y1,y2,x): #straightline function\n",
    "        slope = (y2-y1)/(x2-x1)\n",
    "        return slope*(x-x1)+y1\n",
    "\n",
    "    st_line = []\n",
    "    x = np.linspace(0,50,50).tolist()# [i for i in range(len(trend))]\n",
    "\n",
    "    for i in x :\n",
    "        st_line.append(straight_line(x1,x2,y1,y2,i))   #straightline\n",
    "\n",
    "    resid = [np.abs(st_line[i]-std_list[i])for i in range(len(x))]  # residual calculation\n",
    "    maxi_resid = max(resid)\n",
    "    pos_maxi = resid.index(maxi_resid) #optimal threshold\n",
    "    cut_off = ( pos_maxi + 50 ) / 100\n",
    "\n",
    "T_result = dir_output + output_name + \"_DEOCSU.gff\"\n",
    "T_result_cut = dir_output + output_name + \"_DEOCSU_%s.gff\"%cut_off\n",
    "\n",
    "lst_line, lst_width = [], []\n",
    "with open(dir_final_tsv, \"r\") as fre, open(T_result, \"w\") as final_T, open( T_result_cut, \"w\" ) as final_cut :\n",
    "    lines = fre.readlines()\n",
    "    \n",
    "    for line in lines[1:]:\n",
    "        peak_info = line.split(\"\\t\")\n",
    "        \n",
    "        true_ori = float(peak_info[2])\n",
    "        true_perc = \"Probability_of_true=%.2f%%;\"%(true_ori*100)\n",
    "\n",
    "        acc = peak_info[0].split(\"-\")[0]\n",
    "        loc = int(peak_info[0].split(\"-\")[1])\n",
    "        label = peak_info[1]\n",
    "        lst_width.append(float(peak_info[3]))\n",
    "\n",
    "        x = [ float(peak_info[4]), float(peak_info[5]) ]\n",
    "\n",
    "        start = loc - 128 + int(round( float( min(x) ) ))\n",
    "        end = loc - 128 + int(round( float( max(x) ) ))\n",
    "\n",
    "        if end <0 :\n",
    "            continue\n",
    "        elif start < 0 :\n",
    "            start = 0\n",
    "\n",
    "        new_info = \"%s-%d\"%(acc,start)\n",
    "\n",
    "        if new_info in lst_line:\n",
    "            continue\n",
    "\n",
    "        elif label == \"1\":\n",
    "            attr = \"True;%s;color=FF0000\"%true_perc\n",
    "            w = [ acc, \"DEOCSU_%s\"%output_name, \"DEOCSU_%s\"%output_name, str(start), str(end), \".\", \"+\", \".\", attr ]\n",
    "            final_T.write(\"\\t\".join(w) + \"\\n\")\n",
    "\n",
    "            if true_ori >= cut_off :\n",
    "                w2 = [ acc, \"DEOCSU_%s[%s]\"%(output_name,cut_off), \"DEOCSU_%s[%s]\"%(output_name,cut_off), str(start), str(end), \".\", \"+\", \".\", attr ]\n",
    "                final_cut.write(\"\\t\".join(w2) + \"\\n\")\n",
    "\n",
    "            lst_line.append(new_info)\n",
    "\n",
    "        else:\n",
    "            print (\"Error : Label is not True ---- %s\"%(acc + \"-\" + str(loc)))\n",
    "print (\"Make peak gff - Done ฅ^•ﻌ•^ฅ\")\n",
    "\n",
    "!rm -r $dir_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ba91e",
   "metadata": {},
   "source": [
    "# Post DEOCSU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ef93987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check Width histogram ( All peak )\n",
    "npw =np.array(lst_width)\n",
    "\n",
    "plt.hist(lst_width, bins=20)\n",
    "plt.xlabel('Base pair')\n",
    "plt.ylabel('Number of peaks')\n",
    "\n",
    "plt.title( \"[ %s ] \\n Average binding width = %.2fbp\"%(output_name, np.mean(npw)) )\n",
    "plt.savefig( dir_output + output_name + \".png\" )\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
